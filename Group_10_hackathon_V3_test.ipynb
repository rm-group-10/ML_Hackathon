{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.impute import IterativeImputer, SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error, r2_score, accuracy_score, f1_score, classification_report\n",
        ")\n",
        "\n",
        "from sklearn.ensemble import (\n",
        "    GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier, RandomForestRegressor\n",
        ")\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import (\n",
        "    BayesianRidge, LinearRegression, LogisticRegression\n",
        ")\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import (\n",
        "    StandardScaler, OneHotEncoder, OrdinalEncoder\n",
        ")\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "J5SyGaqaW6KP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lJjHGjb4W4GM"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_csv('/content/dataset_B_testing.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.drop(columns = ['employment_sector'], inplace = True)\n",
        "\n",
        "# Impute categorical columns using mode\n",
        "cat_impute_cols = [\n",
        "    'health_insurance', 'doctor_recc_h1n1', 'rent_or_own', 'employment_status',\n",
        "    'education', 'marital_status', 'income_poverty',\n",
        "    'chronic_med_condition', 'child_under_6_months', 'health_worker'\n",
        "]\n",
        "\n",
        "for col in cat_impute_cols:\n",
        "    if col in df_test.columns:\n",
        "        df_test[col] = df_test[col].fillna(df_test[col].mode()[0])\n",
        "\n",
        "# Impute numeric/behavioral columns using median\n",
        "behavioral_cols = [\n",
        "    'h1n1_concern', 'h1n1_knowledge', 'behavioral_antiviral_meds',\n",
        "    'behavioral_avoidance', 'behavioral_face_mask', 'behavioral_wash_hands',\n",
        "    'behavioral_large_gatherings', 'behavioral_outside_home',\n",
        "    'behavioral_touch_face', 'opinion_h1n1_vacc_effective',\n",
        "    'opinion_h1n1_risk', 'opinion_h1n1_sick_from_vacc',\n",
        "    'household_adults', 'household_children'\n",
        "]\n",
        "\n",
        "for col in behavioral_cols:\n",
        "    if col in df_test.columns:\n",
        "        df_test[col] = df_test[col].fillna(df_test[col].median())\n",
        "\n",
        "# all missing values handled\n",
        "df_test.isnull().sum()[df_test.isnull().sum() > 0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "id": "rIcqYySqW9HE",
        "outputId": "ea7ea60b-ad8c-4648-f4fa-8a5b4787d7a6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Series([], dtype: int64)"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ohe_features = [\"sex\", \"income_poverty\", \"rent_or_own\", \"census_msa\", \"race\"]\n",
        "ord_features = [\"age_group\", \"education\", \"marital_status\", \"employment_status\"]\n",
        "\n",
        "# Ordinal encoding order\n",
        "age_order = [\"18 - 34 Years\", \"35 - 44 Years\", \"45 - 54 Years\", \"55 - 64 Years\", \"65+ Years\"]\n",
        "edu_order = [\"< 12 Years\", \"12 Years\", \"Some College\", \"College Graduate\"]\n",
        "marital_order = [\"Not Married\", \"Married\"]\n",
        "emp_order = [\"Not in Labor Force\", \"Unemployed\", \"Employed\"]\n",
        "ordinal_categories = [age_order, edu_order, marital_order, emp_order]\n",
        "\n",
        "# Pipelines for categorical encoders\n",
        "ohe_tf = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
        "])\n",
        "\n",
        "ord_tf = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"ord\", OrdinalEncoder(\n",
        "        categories=ordinal_categories,\n",
        "        handle_unknown=\"use_encoded_value\",\n",
        "        unknown_value=-1\n",
        "    ))\n",
        "])\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"ohe\", ohe_tf, ohe_features),\n",
        "        (\"ord\", ord_tf, ord_features),\n",
        "    ],\n",
        "    remainder=\"passthrough\"  # <-- keep all unlisted columns\n",
        ")\n",
        "\n",
        "X = df_test.copy()\n",
        "# y = df_test[\"h1n1_vaccine\"]\n",
        "\n",
        "X_transformed = preprocess.fit_transform(X)\n",
        "\n",
        "encoded_names = preprocess.get_feature_names_out()\n",
        "\n",
        "X_prepared = pd.DataFrame(X_transformed, columns=encoded_names, index=df_test.index)"
      ],
      "metadata": {
        "id": "_JTN6LY1XEef"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_prepared.columns = (\n",
        "    X_prepared.columns\n",
        "    .str.lower()\n",
        "    .str.replace('[^a-z0-9]+', '_', regex = True)\n",
        "    .str.strip('_')\n",
        ")"
      ],
      "metadata": {
        "id": "-MLsUF10XNtE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_comp = 0.8\n",
        "\n",
        "pipe = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"pca\", PCA(n_components = n_comp, random_state = 42, svd_solver = \"auto\", whiten = False))\n",
        "])\n",
        "\n",
        "X_pca = pipe.fit_transform(X_prepared)\n",
        "\n",
        "\n",
        "pca_cols = [f\"pc{i+1}\" for i in range(X_pca.shape[1])]\n",
        "PCA_df = pd.DataFrame(X_pca, columns = pca_cols, index = X_prepared.index)\n",
        "\n",
        "explained = pipe.named_steps[\"pca\"].explained_variance_ratio_\n",
        "cum_explained = np.cumsum(explained)"
      ],
      "metadata": {
        "id": "ySgfMZbNXYSY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_pca_red = PCA_df.drop([\"pc21\", \"pc19\", \"pc17\", \"pc13\", \"pc11\", \"pc10\", \"pc1\"], axis = 1)"
      ],
      "metadata": {
        "id": "t0PK-nqcXbJP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_pca_red.head().columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3QLNTIOXeRA",
        "outputId": "0315b33c-d8c0-4596-a19f-fa4114da5aff"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_predict(X, y, model, random_state = 42):\n",
        "\n",
        "    #Split into train/test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size = 0.3, random_state = random_state\n",
        "    )\n",
        "\n",
        "    # Define the model\n",
        "    model = model(random_state = random_state)\n",
        "\n",
        "    # Train the model on original data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    f1 = f1_score(y_test, predictions)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "    if model.__class__.__name__:\n",
        "        print(f\"{model.__class__.__name__} F1 Score:\", f1)\n",
        "        print(f\"{model.__class__.__name__} Accuracy:\", accuracy)\n",
        "    elif model.__name__:\n",
        "        print(f\"{model.__name__} F1 Score:\", f1)\n",
        "        print(f\"{model.__name__} Accuracy:\", accuracy)\n",
        "    else:\n",
        "        print(classification_report(y_test, predictions))\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(classification_report(y_test, predictions))\n",
        "\n",
        "    pred_df = pd.Dataframe(predictions, index = True)\n",
        "\n",
        "    pred_df.to_csv(f\"pred_df{model.__class__.__name__}.csv\")\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, predictions, accuracy, f1"
      ],
      "metadata": {
        "id": "dM3frbmCXrns"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}